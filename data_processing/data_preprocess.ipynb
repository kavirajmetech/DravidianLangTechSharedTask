{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vasantha Raj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-12-25 17:20:39 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 421kB [00:00, 26.8MB/s]                    \n",
      "2024-12-25 17:20:39 INFO: Downloaded file to C:\\Users\\Vasantha Raj\\stanza_resources\\resources.json\n",
      "2024-12-25 17:20:41 INFO: Loading these models for language: ta (Tamil):\n",
      "============================\n",
      "| Processor | Package      |\n",
      "----------------------------\n",
      "| tokenize  | ttb          |\n",
      "| mwt       | ttb          |\n",
      "| pos       | ttb_nocharlm |\n",
      "| lemma     | ttb_nocharlm |\n",
      "| depparse  | ttb_nocharlm |\n",
      "============================\n",
      "\n",
      "2024-12-25 17:20:41 INFO: Using device: cpu\n",
      "2024-12-25 17:20:41 INFO: Loading: tokenize\n",
      "c:\\Users\\Vasantha Raj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "2024-12-25 17:20:41 INFO: Loading: mwt\n",
      "2024-12-25 17:20:41 INFO: Loading: pos\n",
      "2024-12-25 17:20:43 INFO: Loading: lemma\n",
      "2024-12-25 17:20:43 INFO: Loading: depparse\n",
      "2024-12-25 17:20:43 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re\n",
    "import stanza\n",
    "nlp = stanza.Pipeline('ta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>родрпЖройрпНроХро╛роЪро┐ родрпКроХрпБродро┐ рокрпБродро┐роп родрооро┐ро┤роХроорпН роХроЯрпНроЪро┐ ро╡рпЗроЯрпНрокро╛ро│ро░рпН ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>роЕрогрпНрогройрпН роЗродройрпИ роЪрпВроЪроХрооро╛роХ 11 рооро╛родроЩрпНроХро│рпН роорпБройрпНрокрпЗ рокрпЗроЯрпНроЯро┐роп...</td>\n",
       "      <td>Substantiated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>роТро░рпБ ро╡ро░рпБроЯроорпН роЖроХро┐ ро╡ро┐роЯрпНроЯродрпБ роЗроирпНрод родрпБропро░роорпН роирпЗро░рпНроирпНродрпБ......</td>\n",
       "      <td>Opinionated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>роОроЯрокрпНрокро╛роЯро┐ропрпИ роХрогрпНроЯрпБроХрпКро│рпНро│ро╛род \"роОроЯрокрпНрокро╛роЯро┐\"ЁЯлв\\n ---\\nроЖродро░...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>роОроЩрпНроХро│ро┐ройрпН роЕро░роЪро┐ропро▓рпН роЕроЯрпБродрпНрод родро▓рпИроорпБро▒рпИроХрпНроХрпБрооро╛ройродрпБ \\n#роороХ...</td>\n",
       "      <td>Opinionated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content         labels\n",
       "0  родрпЖройрпНроХро╛роЪро┐ родрпКроХрпБродро┐ рокрпБродро┐роп родрооро┐ро┤роХроорпН роХроЯрпНроЪро┐ ро╡рпЗроЯрпНрокро╛ро│ро░рпН ...        Neutral\n",
       "1  роЕрогрпНрогройрпН роЗродройрпИ роЪрпВроЪроХрооро╛роХ 11 рооро╛родроЩрпНроХро│рпН роорпБройрпНрокрпЗ рокрпЗроЯрпНроЯро┐роп...  Substantiated\n",
       "2  роТро░рпБ ро╡ро░рпБроЯроорпН роЖроХро┐ ро╡ро┐роЯрпНроЯродрпБ роЗроирпНрод родрпБропро░роорпН роирпЗро░рпНроирпНродрпБ......    Opinionated\n",
       "3  роОроЯрокрпНрокро╛роЯро┐ропрпИ роХрогрпНроЯрпБроХрпКро│рпНро│ро╛род \"роОроЯрокрпНрокро╛роЯро┐\"ЁЯлв\\n ---\\nроЖродро░...       Positive\n",
       "4  роОроЩрпНроХро│ро┐ройрпН роЕро░роЪро┐ропро▓рпН роЕроЯрпБродрпНрод родро▓рпИроорпБро▒рпИроХрпНроХрпБрооро╛ройродрпБ \\n#роороХ...    Opinionated"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(r\"../data\\PS_train.csv\")\n",
    "data1=pd.read_csv(r'../data\\PS_train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_components(input_text):\n",
    "    # Regex patterns\n",
    "    tamil_regex = r\"[\\u0B80-\\u0BFF\\s]+\"  # Tamil characters\n",
    "    emoji_regex = (\n",
    "        r\"[\\U0001F1E6-\\U0001F1FF]|[\\U0001F300-\\U0001F5FF]|[\\U0001F600-\\U0001F64F]|\"\n",
    "        r\"[\\U0001F680-\\U0001F6FF]|[\\U0001F700-\\U0001F77F]|[\\U0001F780-\\U0001F7FF]|\"\n",
    "        r\"[\\U0001F800-\\U0001F8FF]|[\\U0001F900-\\U0001F9FF]|[\\U0001FA00-\\U0001FA6F]|\"\n",
    "        r\"[\\U0001FA70-\\U0001FAFF]|[\\U00002702-\\U000027B0]|[\\U000024C2-\\U0001F251]|\"\n",
    "        r\"[\\U0001F004]|[\\U0001F0CF]|[\\u2600-\\u26FF]|[\\u2700-\\u27BF]|[\\uFE0F]|[\\u2300-\\u23FF]\"\n",
    "    )\n",
    "    hashtag_regex = r\"#\\S+\"  # Hashtags\n",
    "    \n",
    "    # Results\n",
    "    tamil_sentences = []\n",
    "    emojis = []\n",
    "    tags = []\n",
    "    \n",
    "    # Split input into lines\n",
    "    lines = [line.strip() for line in input_text.splitlines() if line.strip()]\n",
    "    \n",
    "    for line in lines:\n",
    "        # Extract Tamil sentences\n",
    "        tamil_matches = re.findall(tamil_regex, line)\n",
    "        if tamil_matches:\n",
    "            tamil_sentences.extend([match.strip() for match in tamil_matches if match.strip()])\n",
    "        \n",
    "        # Extract emojis\n",
    "        emoji_matches = re.findall(emoji_regex, line)\n",
    "        if emoji_matches:\n",
    "            emojis.extend(emoji_matches)\n",
    "        \n",
    "        # Extract hashtags\n",
    "        hashtag_matches = re.findall(hashtag_regex, line)\n",
    "        if hashtag_matches:\n",
    "            tags.extend(hashtag_matches)\n",
    "    query=\" \".join(tamil_sentences)\n",
    "    doc = nlp(query)\n",
    "    tokens=[]\n",
    "    lemma=[]\n",
    "    pos=[]\n",
    "    dependancy_relation=[]\n",
    "    for sentence in doc.sentences:\n",
    "        for word in sentence.words:\n",
    "            tokens.append(word.text)\n",
    "            lemma.append(word.lemma)\n",
    "            pos.append(word.upos)\n",
    "            dependancy_relation.append(word.deprel)\n",
    "    return {\n",
    "        \"tamil_sentences\": [query],\n",
    "        \"emojis\": emojis,\n",
    "        \"tags\": tags,\n",
    "        \"tokens\":tokens,\n",
    "        \"lemmas\":lemma,\n",
    "        \"pos\":pos,\n",
    "        \"dependancy_relation\":dependancy_relation\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content']=data['content'].apply(extract_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dev and train both are same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "родрпЖройрпНроХро╛роЪро┐ родрпКроХрпБродро┐ рокрпБродро┐роп родрооро┐ро┤роХроорпН роХроЯрпНроЪро┐ ро╡рпЗроЯрпНрокро╛ро│ро░рпН роЯро╛роХрпНроЯро░рпН. роХро┐ро░рпБро╖рпНрогроЪро╛рооро┐ропрпИ  роЖродро░ро┐родрпНродрпБ родрпЗроорпБродро┐роХ рокрпКродрпБроЪрпН роЪрпЖропро▓ро╛ро│ро░рпН рокро┐ро░рпЗрооро▓родро╛ ро╡ро┐роЬропроХро╛роирпНродрпН  ро╕рпНро░рпАро╡ро┐ро▓рпНро▓ро┐рокрпБродрпНродрпВро░ро┐ро▓рпН рокро┐ро░роЪрпНроЪро╛ро░роорпН.\n",
      "#News18TamilNadu #LokSabaElection2024  Neutral\n",
      "-----------------------------------------------\n",
      "роЕрогрпНрогройрпН роЗродройрпИ роЪрпВроЪроХрооро╛роХ 11 рооро╛родроЩрпНроХро│рпН роорпБройрпНрокрпЗ рокрпЗроЯрпНроЯро┐ропро┐ро▓рпН роЪрпКро▓рпНро▓ро┐роЯрпНроЯро╛ро░рпН..!\n",
      "\n",
      "           Substantiated\n",
      "-----------------------------------------------\n",
      "роТро░рпБ ро╡ро░рпБроЯроорпН роЖроХро┐ ро╡ро┐роЯрпНроЯродрпБ роЗроирпНрод родрпБропро░роорпН роирпЗро░рпНроирпНродрпБ... роЗройрпНро▒рпБро╡ро░рпИ роТро░рпБ роЖрогро┐ропрпИ роХрпВроЯ рокро┐роЯрпБроЩрпНроХро╛род родрооро┐ро┤роХ роЕро░роЪрпБ\n",
      "\n",
      "#DMKFailsTN\n",
      "\n",
      "\n",
      "\n",
      " Opinionated\n",
      "-----------------------------------------------\n",
      "роОроЯрокрпНрокро╛роЯро┐ропрпИ роХрогрпНроЯрпБроХрпКро│рпНро│ро╛род \"роОроЯрокрпНрокро╛роЯро┐\"ЁЯлв\n",
      " ---\n",
      "роЖродро░ро┐рокрпНрокрпАро░рпН ЁЯМД роЙродропроЪрпВро░ро┐ропройрпН ЁЯП┤ЁЯЪй\n",
      "---\n",
      "\n",
      "#роороХрпНроХро│ро┐ройрпНроХрпБро░ро▓рпН #роУрооро▓рпВро░рпН #роЪрпЗро▓роорпН #роЪрпЗро▓роорпН4роЪрпЖро▓рпНро╡роХрогрокродро┐ #Vote4DMK #Vote4INDIA   Stalin #Testimonials QA #роЪрпЗро▓роорпНродрпЖро▒рпНроХрпБ #роЪрпЗро▓роорпНро╡роЯроХрпНроХрпБ #роОроЯрокрпНрокро╛роЯро┐ #роЪрпЗро▓роорпНроорпЗро▒рпНроХрпБ #Eps #Edappadi #Palanisamy  Positive\n",
      "-----------------------------------------------\n",
      "роОроЩрпНроХро│ро┐ройрпН роЕро░роЪро┐ропро▓рпН роЕроЯрпБродрпНрод родро▓рпИроорпБро▒рпИроХрпНроХрпБрооро╛ройродрпБ \n",
      "#роороХрпНроХро│ро┐ройрпН_роЪро┐ройрпНройроорпН_роорпИроХрпН  Opinionated\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(data1['content'][i],data1['labels'][i])\n",
    "    print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tamil_sentences': ['родрпЖройрпНроХро╛роЪро┐ родрпКроХрпБродро┐ рокрпБродро┐роп родрооро┐ро┤роХроорпН роХроЯрпНроЪро┐ ро╡рпЗроЯрпНрокро╛ро│ро░рпН роЯро╛роХрпНроЯро░рпН роХро┐ро░рпБро╖рпНрогроЪро╛рооро┐ропрпИ  роЖродро░ро┐родрпНродрпБ родрпЗроорпБродро┐роХ рокрпКродрпБроЪрпН роЪрпЖропро▓ро╛ро│ро░рпН рокро┐ро░рпЗрооро▓родро╛ ро╡ро┐роЬропроХро╛роирпНродрпН  ро╕рпНро░рпАро╡ро┐ро▓рпНро▓ро┐рокрпБродрпНродрпВро░ро┐ро▓рпН рокро┐ро░роЪрпНроЪро╛ро░роорпН'], 'emojis': [], 'tags': ['#News18TamilNadu', '#LokSabaElection2024'], 'tokens': ['родрпЖройрпНроХро╛роЪро┐', 'родрпКроХрпБродро┐', 'рокрпБродро┐роп', 'родрооро┐ро┤роХроорпН', 'роХроЯрпНроЪро┐', 'ро╡рпЗроЯрпНрокро╛ро│ро░рпН', 'роЯро╛роХрпНроЯро░рпН', 'роХро┐ро░рпБро╖рпНрогроЪро╛рооро┐ропрпИ', 'роЖродро░ро┐родрпНродрпБ', 'родрпЗроорпБродро┐роХ', 'рокрпКродрпБроЪрпН', 'роЪрпЖропро▓ро╛ро│ро░рпН', 'рокро┐ро░рпЗрооро▓родро╛', 'ро╡ро┐роЬропроХро╛роирпНродрпН', 'ро╕рпНро░рпАро╡ро┐ро▓рпНро▓ро┐рокрпБродрпНродрпВро░ро┐ро▓рпН', 'рокро┐ро░роЪрпНроЪро╛ро░роорпН'], 'lemmas': ['родрпЖройрпНроХро╛роЪро┐', 'родрпКроХрпБродро┐', 'рокрпБродро┐роп', 'родрооро┐ро┤роХроорпН', 'роХроЯрпНроЪро┐', 'ро╡рпЗроЯрпНрокро╛ро│ро░рпН', 'роЯро╛роХрпНроЯро░рпН', 'роХро┐ро░рпБро╖рпНрогроЪро╛рооро┐', 'роЖродро░ро┐', 'родрпЗроорпБродро┐роХ', 'рокрпКродрпБ', 'роЪрпЖропро▓ро╛ро│ро░рпН', 'рокро┐ро░рпЗрооро▓родро╛', 'ро╡ро┐роЬропроХро╛роирпНродрпН', 'ро╕рпНро░рпАро╡ро┐ро▓рпНро▓ро┐рокрпБродрпНродрпВрпН', 'рокро┐ро░роЪрпНроЪро╛ро░роорпН'], 'pos': ['PROPN', 'NOUN', 'ADJ', 'PROPN', 'NOUN', 'NOUN', 'PROPN', 'PROPN', 'VERB', 'PROPN', 'NOUN', 'NOUN', 'PROPN', 'PROPN', 'PROPN', 'NOUN'], 'dependancy_relation': ['nmod', 'nmod', 'amod', 'nmod', 'nmod', 'nsubj', 'nmod', 'obj', 'amod', 'nmod', 'nmod', 'nmod', 'nmod', 'nsubj', 'obl', 'root']} Neutral\n",
      "-----------------------------------------------\n",
      "{'tamil_sentences': ['роЕрогрпНрогройрпН роЗродройрпИ роЪрпВроЪроХрооро╛роХ рооро╛родроЩрпНроХро│рпН роорпБройрпНрокрпЗ рокрпЗроЯрпНроЯро┐ропро┐ро▓рпН роЪрпКро▓рпНро▓ро┐роЯрпНроЯро╛ро░рпН'], 'emojis': [], 'tags': [], 'tokens': ['роЕрогрпНрогройрпН', 'роЗродройрпИ', 'роЪрпВроЪроХрооро╛роХ', 'рооро╛родроЩрпНроХро│рпН', 'роорпБройрпНрокрпЗ', 'рокрпЗроЯрпНроЯро┐ропро┐ро▓рпН', 'роЪрпКро▓рпНро▓ро┐роЯрпНроЯро╛ро░рпН'], 'lemmas': ['роЕрогрпНрогройрпН', 'роЗродрпБ', 'роЪрпВроЪроХроорпН', 'рооро╛родроорпН', 'роорпБройрпНрокрпЗ', 'рокрпЗроЯрпНроЯро┐', 'роЪрпКро▓рпНро▓ро┐роЯрпБ'], 'pos': ['PROPN', 'PRON', 'ADV', 'NOUN', 'ADP', 'NOUN', 'VERB'], 'dependancy_relation': ['nmod', 'obj', 'advmod', 'obl', 'case', 'obl', 'root']} Substantiated\n",
      "-----------------------------------------------\n",
      "{'tamil_sentences': ['роТро░рпБ ро╡ро░рпБроЯроорпН роЖроХро┐ ро╡ро┐роЯрпНроЯродрпБ роЗроирпНрод родрпБропро░роорпН роирпЗро░рпНроирпНродрпБ роЗройрпНро▒рпБро╡ро░рпИ роТро░рпБ роЖрогро┐ропрпИ роХрпВроЯ рокро┐роЯрпБроЩрпНроХро╛род родрооро┐ро┤роХ роЕро░роЪрпБ'], 'emojis': [], 'tags': ['#DMKFailsTN'], 'tokens': ['роТро░рпБ', 'ро╡ро░рпБроЯроорпН', 'роЖроХро┐', 'ро╡ро┐роЯрпНроЯродрпБ', 'роЗроирпНрод', 'родрпБропро░роорпН', 'роирпЗро░рпНроирпНродрпБ', 'роЗройрпНро▒рпБро╡ро░рпИ', 'роТро░рпБ', 'роЖрогро┐ропрпИ', 'роХрпВроЯ', 'рокро┐роЯрпБроЩрпНроХро╛род', 'родрооро┐ро┤роХ', 'роЕро░роЪрпБ'], 'lemmas': ['роТро░рпБ', 'ро╡ро░рпБроЯроорпН', 'роЖроХро┐', 'ро╡ро┐роЯрпБ', 'роЗроирпНрод', 'родрпБропро░роорпН', 'роирпЗро░рпН', 'роЗройрпНро▒рпБро╡ро░рпИ', 'роТро░рпБ', 'роЖрогро┐', 'роХрпВроЯрпБ', 'рокро┐роЯрпБроЩрпНроХрпБ', 'родрооро┐ро┤роХроорпН', 'роЕро░роЪрпБ'], 'pos': ['ADJ', 'NOUN', 'ADV', 'VERB', 'DET', 'NOUN', 'VERB', 'ADV', 'ADJ', 'NOUN', 'PART', 'VERB', 'PROPN', 'NOUN'], 'dependancy_relation': ['amod', 'nsubj', 'advmod', 'advcl', 'det', 'obj', 'advcl', 'advmod', 'amod', 'obj', 'advmod:emph', 'root', 'nmod', 'nsubj']} Opinionated\n",
      "-----------------------------------------------\n",
      "{'tamil_sentences': ['роОроЯрокрпНрокро╛роЯро┐ропрпИ роХрогрпНроЯрпБроХрпКро│рпНро│ро╛род роОроЯрокрпНрокро╛роЯро┐ роЖродро░ро┐рокрпНрокрпАро░рпН роЙродропроЪрпВро░ро┐ропройрпН роороХрпНроХро│ро┐ройрпНроХрпБро░ро▓рпН роУрооро▓рпВро░рпН роЪрпЗро▓роорпН роЪрпЗро▓роорпН роЪрпЖро▓рпНро╡роХрогрокродро┐ роЪрпЗро▓роорпНродрпЖро▒рпНроХрпБ роЪрпЗро▓роорпНро╡роЯроХрпНроХрпБ роОроЯрокрпНрокро╛роЯро┐ роЪрпЗро▓роорпНроорпЗро▒рпНроХрпБ'], 'emojis': ['ЁЯлв', 'ЁЯМД', 'ЁЯП┤', 'ЁЯЪй'], 'tags': ['#роороХрпНроХро│ро┐ройрпНроХрпБро░ро▓рпН', '#роУрооро▓рпВро░рпН', '#роЪрпЗро▓роорпН', '#роЪрпЗро▓роорпН4роЪрпЖро▓рпНро╡роХрогрокродро┐', '#Vote4DMK', '#Vote4INDIA', '#Testimonials', '#роЪрпЗро▓роорпНродрпЖро▒рпНроХрпБ', '#роЪрпЗро▓роорпНро╡роЯроХрпНроХрпБ', '#роОроЯрокрпНрокро╛роЯро┐', '#роЪрпЗро▓роорпНроорпЗро▒рпНроХрпБ', '#Eps', '#Edappadi', '#Palanisamy'], 'tokens': ['роОроЯрокрпНрокро╛роЯро┐ропрпИ', 'роХрогрпНроЯрпБроХрпКро│рпНро│ро╛род', 'роОроЯрокрпНрокро╛роЯро┐', 'роЖродро░ро┐рокрпНрокрпАро░рпН', 'роЙродропроЪрпВро░ро┐ропройрпН', 'роороХрпНроХро│ро┐ройрпНроХрпБро░ро▓рпН', 'роУрооро▓рпВро░рпН', 'роЪрпЗро▓роорпН', 'роЪрпЗро▓роорпН', 'роЪрпЖро▓рпНро╡роХрогрокродро┐', 'роЪрпЗро▓роорпНродрпЖро▒рпНроХрпБ', 'роЪрпЗро▓роорпНро╡роЯроХрпНроХрпБ', 'роОроЯрокрпНрокро╛роЯро┐', 'роЪрпЗро▓роорпНроорпЗро▒рпНроХрпБ'], 'lemmas': ['роОроЯрокрпНрокро╛роЯро┐', 'роХрогрпНроЯрпБроХрпКро│рпН', 'роОроЯрокрпНрокро╛роЯро┐', 'роЖродро░ро┐рокрпНрокрпАро░рпН', 'роЙродропроЪрпВро░ро┐ропройрпН', 'роороХрпНроХро│рпН', 'роУрооро▓рпВро░рпН', 'роЪрпЗро▓роорпН', 'роЪрпЗро▓роорпН', 'роЪрпЖро▓рпНро╡роХрогрокродро┐', 'роЪрпЗро▓роорпНродрпЖро▒рпНроХрпБ', 'роЪрпЗро▓роорпН', 'роОроЯрокрпНрокро╛роЯро┐', 'роЪрпЗро▓роорпНроорпЗ'], 'pos': ['PROPN', 'VERB', 'PROPN', 'NOUN', 'NOUN', 'NOUN', 'PROPN', 'PROPN', 'PROPN', 'PROPN', 'NOUN', 'NOUN', 'PROPN', 'VERB'], 'dependancy_relation': ['obj', 'advcl', 'nmod', 'nmod', 'nmod', 'nmod', 'nmod', 'nmod', 'nmod', 'nsubj', 'obl:arg', 'obl', 'nmod', 'root']} Positive\n",
      "-----------------------------------------------\n",
      "{'tamil_sentences': ['роОроЩрпНроХро│ро┐ройрпН роЕро░роЪро┐ропро▓рпН роЕроЯрпБродрпНрод родро▓рпИроорпБро▒рпИроХрпНроХрпБрооро╛ройродрпБ роороХрпНроХро│ро┐ройрпН роЪро┐ройрпНройроорпН роорпИроХрпН'], 'emojis': [], 'tags': ['#роороХрпНроХро│ро┐ройрпН_роЪро┐ройрпНройроорпН_роорпИроХрпН'], 'tokens': ['роОроЩрпНроХро│ро┐ройрпН', 'роЕро░роЪро┐ропро▓рпН', 'роЕроЯрпБродрпНрод', 'родро▓рпИроорпБро▒рпИроХрпНроХрпНроХрпБроорпН', 'роЖройродрпБ', 'роороХрпНроХро│ро┐ройрпН', 'роЪро┐ройрпНройроорпН', 'роорпИроХрпН'], 'lemmas': ['роОроЩрпНроХро│рпН', 'роЕро░роЪро┐ропро▓рпН', 'роЕроЯрпБродрпНрод', 'родро▓рпИроорпБро▒рпИ', 'роЖройродрпБ', 'роороХрпНроХро│рпН', 'роЪро┐ройрпНройроорпН', 'роорпИроХрпН'], 'pos': ['PRON', 'NOUN', 'ADJ', 'NOUN', 'VERB', 'NOUN', 'NOUN', 'NOUN'], 'dependancy_relation': ['nmod', 'nmod', 'amod', 'obl', 'ccomp', 'nmod', 'root', 'nmod']} Opinionated\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(data['content'][i],data['labels'][i])\n",
    "    print('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutral', 'Substantiated', 'Opinionated', 'Positive', 'Sarcastic',\n",
       "       'Negative', 'None of the above'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={'Neutral':0, 'Substantiated':1, 'Opinionated':2, 'Positive':5, 'Sarcastic':4,\n",
    "       'Negative':-5, 'None of the above':-1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['labels']=data['labels'].apply(lambda x: d[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"preprocessed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vasantha Raj\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 421kB [00:00, 54.0MB/s]                    \n",
      "2024-12-25 15:22:48 INFO: Downloaded file to C:\\Users\\Vasantha Raj\\stanza_resources\\resources.json\n",
      "2024-12-25 15:22:48 INFO: Downloading default packages for language: ta (Tamil) ...\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-ta/resolve/v1.10.0/models/default.zip: 100%|тЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИтЦИ| 377M/377M [10:16<00:00, 611kB/s]    \n",
      "2024-12-25 15:33:06 INFO: Downloaded file to C:\\Users\\Vasantha Raj\\stanza_resources\\ta\\default.zip\n",
      "2024-12-25 15:33:09 INFO: Finished downloading models and saved to C:\\Users\\Vasantha Raj\\stanza_resources\n"
     ]
    }
   ],
   "source": [
    "# import stanza\n",
    "# stanza.download('ta')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
